"""
License Plate Detection Training Script
Script hu·∫•n luy·ªán m√¥ h√¨nh YOLOv8 ƒë·ªÉ ph√°t hi·ªán bi·ªÉn s·ªë xe
"""

import sys
import os
from pathlib import Path
import argparse
from ultralytics import YOLO
import yaml

# Add src to path
sys.path.append(str(Path(__file__).parent.parent / "src"))

from src.utils.logger import setup_logger


def create_license_plate_dataset_yaml(data_dir: Path, output_path: Path):
    """T·∫°o file dataset.yaml cho YOLO training bi·ªÉn s·ªë"""
    
    dataset_config = {
        'path': str(data_dir),
        'train': 'images/train',
        'val': 'images/val',
        'test': 'images/test',
        'nc': 1,  # Number of classes (ch·ªâ c√≥ 1 class: license_plate)
        'names': {
            0: 'license_plate'
        }
    }
    
    with open(output_path, 'w') as f:
        yaml.dump(dataset_config, f, default_flow_style=False)
    
    print(f"‚úÖ ƒê√£ t·∫°o license plate dataset config: {output_path}")


def train_license_plate_detection(
    data_yaml: str,
    model_size: str = "yolov8s",
    epochs: int = 150,
    batch_size: int = 32,
    img_size: int = 640,
    device: str = "0",
    project: str = "license_plate_detection",
    name: str = "train"
):
    """
    Hu·∫•n luy·ªán m√¥ h√¨nh YOLOv8 ƒë·ªÉ ph√°t hi·ªán bi·ªÉn s·ªë xe
    
    Args:
        data_yaml: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file dataset.yaml
        model_size: K√≠ch th∆∞·ªõc model (yolov8n, yolov8s, yolov8m, yolov8l, yolov8x)
        epochs: S·ªë epochs training
        batch_size: Batch size
        img_size: K√≠ch th∆∞·ªõc ·∫£nh input
        device: GPU device (0, 1, ... ho·∫∑c 'cpu')
        project: T√™n project
        name: T√™n experiment
    """
    
    logger = setup_logger()
    logger.info("üöÄ B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh ph√°t hi·ªán bi·ªÉn s·ªë...")
    
    try:
        # Load model
        model = YOLO(f"{model_size}.pt")
        logger.info(f"üì¶ ƒê√£ load model: {model_size}")
        
        # Start training v·ªõi hyperparameters t·ªëi ∆∞u cho bi·ªÉn s·ªë
        results = model.train(
            data=data_yaml,
            epochs=epochs,
            batch=batch_size,
            imgsz=img_size,
            device=device,
            project=project,
            name=name,
            save=True,
            save_period=10,
            cache=True,
            amp=True,
            patience=30,  # Patience cao h∆°n cho bi·ªÉn s·ªë
            
            # Hyperparameters t·ªëi ∆∞u cho bi·ªÉn s·ªë xe
            lr0=0.01,
            lrf=0.01,
            momentum=0.937,
            weight_decay=0.0005,
            warmup_epochs=3.0,
            warmup_momentum=0.8,
            warmup_bias_lr=0.1,
            
            # Data augmentation ph√π h·ª£p v·ªõi bi·ªÉn s·ªë
            hsv_h=0.01,  # √çt thay ƒë·ªïi hue
            hsv_s=0.5,   # V·ª´a ph·∫£i saturation
            hsv_v=0.3,   # √çt thay ƒë·ªïi brightness
            degrees=5.0, # √çt rotation
            translate=0.05, # √çt d·ªãch chuy·ªÉn
            scale=0.3,   # √çt scale
            shear=2.0,   # M·ªôt ch√∫t perspective
            perspective=0.0001,
            flipud=0.0,  # Kh√¥ng l·∫≠t d·ªçc
            fliplr=0.2,  # √çt l·∫≠t ngang
            mosaic=0.8,  # Gi·∫£m mosaic
            mixup=0.1,   # √çt mixup
            copy_paste=0.0,
            
            # Class weights (n·∫øu c·∫ßn)
            cls=0.5,
            box=7.5,
            dfl=1.5,
            
            # NMS settings
            iou=0.7,
            conf=0.25
        )
        
        logger.info("‚úÖ Ho√†n th√†nh training bi·ªÉn s·ªë!")
        logger.info(f"üìä K·∫øt qu·∫£ training:")
        logger.info(f"   - mAP50: {results.results_dict.get('metrics/mAP50(B)', 'N/A')}")
        logger.info(f"   - mAP50-95: {results.results_dict.get('metrics/mAP50-95(B)', 'N/A')}")
        logger.info(f"   - Precision: {results.results_dict.get('metrics/precision(B)', 'N/A')}")
        logger.info(f"   - Recall: {results.results_dict.get('metrics/recall(B)', 'N/A')}")
        
        # Save best model
        best_model_path = Path(project) / name / "weights" / "best.pt"
        if best_model_path.exists():
            models_dir = Path("data/models")
            models_dir.mkdir(parents=True, exist_ok=True)
            
            import shutil
            shutil.copy2(best_model_path, models_dir / "license_plate_yolov8.pt")
            logger.info(f"üíæ ƒê√£ l∆∞u model bi·ªÉn s·ªë t·ªët nh·∫•t: data/models/license_plate_yolov8.pt")
        
        return results
        
    except Exception as e:
        logger.error(f"‚ùå L·ªói training bi·ªÉn s·ªë: {e}")
        raise


def prepare_license_plate_dataset(data_dir: Path):
    """T·∫°o c·∫•u tr√∫c dataset cho bi·ªÉn s·ªë xe"""
    
    subdirs = [
        "images/train",
        "images/val",
        "images/test", 
        "labels/train",
        "labels/val",
        "labels/test"
    ]
    
    for subdir in subdirs:
        (data_dir / subdir).mkdir(parents=True, exist_ok=True)
    
    print(f"‚úÖ ƒê√£ t·∫°o c·∫•u tr√∫c dataset bi·ªÉn s·ªë t·∫°i: {data_dir}")
    print("üìù H∆∞·ªõng d·∫´n chu·∫©n b·ªã data bi·ªÉn s·ªë:")
    print("   1. Thu th·∫≠p ·∫£nh c√≥ ch·ª©a bi·ªÉn s·ªë xe (t·ªëi thi·ªÉu 5000+ ·∫£nh)")
    print("   2. Annotation bi·ªÉn s·ªë v·ªõi bounding box")
    print("   3. Format YOLO: 0 x_center y_center width height (normalized)")
    print("   4. Chia dataset: 70% train, 20% val, 10% test")
    print("   5. ƒê·∫£m b·∫£o ch·∫•t l∆∞·ª£ng ·∫£nh t·ªët v√† ƒëa d·∫°ng ƒëi·ªÅu ki·ªán √°nh s√°ng")
    
    # T·∫°o file h∆∞·ªõng d·∫´n
    guide_file = data_dir / "annotation_guide.txt"
    with open(guide_file, "w", encoding="utf-8") as f:
        f.write("""
H∆∞·ªõng d·∫´n t·∫°o dataset bi·ªÉn s·ªë xe Vi·ªát Nam

1. Thu th·∫≠p d·ªØ li·ªáu:
   - ·∫¢nh xe c√≥ bi·ªÉn s·ªë r√µ r√†ng
   - ƒêa d·∫°ng g√≥c ch·ª•p: th·∫≥ng, nghi√™ng, xa, g·∫ßn
   - ƒêa d·∫°ng ƒëi·ªÅu ki·ªán: ban ng√†y, ban ƒë√™m, m∆∞a, n·∫Øng
   - ƒêa d·∫°ng lo·∫°i xe: √¥ t√¥, xe m√°y, xe t·∫£i
   - ƒêa d·∫°ng lo·∫°i bi·ªÉn s·ªë: tr·∫Øng, v√†ng, xanh

2. Annotation:
   - S·ª≠ d·ª•ng LabelImg ho·∫∑c Roboflow
   - Ch·ªâ annotation v√πng bi·ªÉn s·ªë (kh√¥ng annotation xe)
   - Bounding box bao tr·ªçn bi·ªÉn s·ªë
   - Class: 0 (license_plate)

3. ƒê·ªãnh d·∫°ng YOLO:
   - File .txt c√πng t√™n v·ªõi ·∫£nh
   - M·ªói d√≤ng: class_id x_center y_center width height
   - T·∫•t c·∫£ gi√° tr·ªã normalized t·ª´ 0-1
   - V√≠ d·ª•: 0 0.5 0.3 0.2 0.1

4. Ki·ªÉm tra ch·∫•t l∆∞·ª£ng:
   - ·∫¢nh kh√¥ng m·ªù, kh√¥ng b·ªã che khu·∫•t
   - Bi·ªÉn s·ªë ƒë·ªçc ƒë∆∞·ª£c b·∫±ng m·∫Øt th∆∞·ªùng
   - Annotation ch√≠nh x√°c, kh√¥ng thi·∫øu s√≥t

5. Dataset t·ªët:
   - T·ªëi thi·ªÉu 5000 ·∫£nh cho training
   - 1000 ·∫£nh cho validation
   - 500 ·∫£nh cho testing
   - C√¢n b·∫±ng c√°c lo·∫°i bi·ªÉn s·ªë v√† ƒëi·ªÅu ki·ªán
""")
    
    print(f"üìñ ƒê√£ t·∫°o h∆∞·ªõng d·∫´n: {guide_file}")


def main():
    parser = argparse.ArgumentParser(description="License Plate Detection Training")
    parser.add_argument("--data", type=str, default="data/license_plate_dataset",
                       help="ƒê∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c dataset bi·ªÉn s·ªë")
    parser.add_argument("--model", type=str, default="yolov8s",
                       choices=["yolov8n", "yolov8s", "yolov8m", "yolov8l", "yolov8x"],
                       help="K√≠ch th∆∞·ªõc model YOLOv8")
    parser.add_argument("--epochs", type=int, default=150,
                       help="S·ªë epochs training")
    parser.add_argument("--batch", type=int, default=32,
                       help="Batch size")
    parser.add_argument("--img-size", type=int, default=640,
                       help="K√≠ch th∆∞·ªõc ·∫£nh input")
    parser.add_argument("--device", type=str, default="0",
                       help="GPU device (0, 1, ... ho·∫∑c 'cpu')")
    parser.add_argument("--setup-only", action="store_true",
                       help="Ch·ªâ t·∫°o c·∫•u tr√∫c dataset, kh√¥ng training")
    
    args = parser.parse_args()
    
    data_dir = Path(args.data)
    
    if args.setup_only:
        prepare_license_plate_dataset(data_dir)
        return
    
    # Ki·ªÉm tra dataset
    if not data_dir.exists():
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y dataset bi·ªÉn s·ªë: {data_dir}")
        print("üí° S·ª≠ d·ª•ng --setup-only ƒë·ªÉ t·∫°o c·∫•u tr√∫c dataset")
        return
    
    # T·∫°o dataset.yaml
    dataset_yaml = data_dir / "dataset.yaml"
    create_license_plate_dataset_yaml(data_dir, dataset_yaml)
    
    # B·∫Øt ƒë·∫ßu training
    train_license_plate_detection(
        data_yaml=str(dataset_yaml),
        model_size=args.model,
        epochs=args.epochs,
        batch_size=args.batch,
        img_size=args.img_size,
        device=args.device
    )


if __name__ == "__main__":
    main()
